{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e53bd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/nlptown/nlp-notebooks/blob/master/Intent%20Classification%20with%20Small%20Transformers.ipynb\n",
    "#https://raw.githubusercontent.com/huggingface/datasets/1.4.1/datasets/banking77/banking77.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77547e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca4c1db07cb54fe8943f3d58778ea9c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading builder script:   0%|          | 0.00/7.46k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90f7e70de101435099a8953238a7c5b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading metadata:   0%|          | 0.00/5.89k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3f04aa44f89466cbf26349098acd94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/14.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/zaarr/.cache/huggingface/modules/datasets_modules/datasets/banking77/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4/banking77.py:59: FutureWarning: Dataset 'banking77' is deprecated and will be deleted. Use 'PolyAI/banking77' instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset banking77/default to /Users/zaarr/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebc6efa6e7224eae9a9b87a1d4182d0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/158k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4dbec3c0dd6541af8c1a32d145bd240d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/51.1k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/10003 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split:   0%|          | 0/3080 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset banking77 downloaded and prepared to /Users/zaarr/.cache/huggingface/datasets/banking77/default/1.1.0/9898c11f6afa9521953d2ef205667b527bad14ef9cab445d470f16240c8c8ec4. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef5109bbeb4047ac88f26e89b48560a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 10003\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 3080\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('banking77')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5329d313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': Value(dtype='string', id=None),\n",
       " 'label': ClassLabel(names=['activate_my_card', 'age_limit', 'apple_pay_or_google_pay', 'atm_support', 'automatic_top_up', 'balance_not_updated_after_bank_transfer', 'balance_not_updated_after_cheque_or_cash_deposit', 'beneficiary_not_allowed', 'cancel_transfer', 'card_about_to_expire', 'card_acceptance', 'card_arrival', 'card_delivery_estimate', 'card_linking', 'card_not_working', 'card_payment_fee_charged', 'card_payment_not_recognised', 'card_payment_wrong_exchange_rate', 'card_swallowed', 'cash_withdrawal_charge', 'cash_withdrawal_not_recognised', 'change_pin', 'compromised_card', 'contactless_not_working', 'country_support', 'declined_card_payment', 'declined_cash_withdrawal', 'declined_transfer', 'direct_debit_payment_not_recognised', 'disposable_card_limits', 'edit_personal_details', 'exchange_charge', 'exchange_rate', 'exchange_via_app', 'extra_charge_on_statement', 'failed_transfer', 'fiat_currency_support', 'get_disposable_virtual_card', 'get_physical_card', 'getting_spare_card', 'getting_virtual_card', 'lost_or_stolen_card', 'lost_or_stolen_phone', 'order_physical_card', 'passcode_forgotten', 'pending_card_payment', 'pending_cash_withdrawal', 'pending_top_up', 'pending_transfer', 'pin_blocked', 'receiving_money', 'Refund_not_showing_up', 'request_refund', 'reverted_card_payment?', 'supported_cards_and_currencies', 'terminate_account', 'top_up_by_bank_transfer_charge', 'top_up_by_card_charge', 'top_up_by_cash_or_cheque', 'top_up_failed', 'top_up_limits', 'top_up_reverted', 'topping_up_by_card', 'transaction_charged_twice', 'transfer_fee_charged', 'transfer_into_account', 'transfer_not_received_by_recipient', 'transfer_timing', 'unable_to_verify_identity', 'verify_my_identity', 'verify_source_of_funds', 'verify_top_up', 'virtual_card_not_working', 'visa_or_mastercard', 'why_verify_identity', 'wrong_amount_of_cash_received', 'wrong_exchange_rate_for_cash_withdrawal'], id=None)}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"train\"].features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44203a2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I am still waiting on my card?\n",
      "What can I do if my card still hasn't arrived after 2 weeks?\n",
      "I have been waiting over a week. Is the card still coming?\n",
      "Can I track my card while it is in the process of delivery?\n",
      "How do I know if I will get my card, or if it is lost?\n"
     ]
    }
   ],
   "source": [
    "for item in dataset[\"train\"][\"text\"][:5]:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa83a5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "train_texts = [item[\"text\"] for item in dataset[\"train\"]]\n",
    "train_labels = [item[\"label\"] for item in dataset[\"train\"]]\n",
    "\n",
    "test_texts = [item[\"text\"] for item in dataset[\"test\"]]\n",
    "test_labels = [item[\"label\"] for item in dataset[\"test\"]]\n",
    "\n",
    "label_counter = Counter(train_labels)\n",
    "label_names = dataset[\"train\"].features[\"label\"].names\n",
    "label_frequencies = {label_names[label]: [label_counter[label]] for label in label_counter}\n",
    "\n",
    "df = pd.DataFrame.from_dict(label_frequencies, orient=\"index\", columns=[\"frequency\"])\n",
    "df = df.sort_values(\"frequency\", ascending=False)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "ax = df.transpose().plot(kind=\"bar\", rot=0)\n",
    "ax.get_legend().remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12913815",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 9002\n",
      "Dev: 1001\n",
      "Test: 3080\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_texts, dev_texts, train_labels, dev_labels = train_test_split(train_texts, \n",
    "                                                                    train_labels, \n",
    "                                                                    test_size=0.1, \n",
    "                                                                    shuffle=True, \n",
    "                                                                    random_state=1)\n",
    "\n",
    "print(\"Train:\", len(train_texts))\n",
    "print(\"Dev:\", len(dev_texts))\n",
    "print(\"Test:\", len(test_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bad916a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "class ClassificationDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['label'] = self.labels[idx]\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8acbef9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': acc\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4b3c0076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** prajjwal1/bert-tiny ***\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a30ce721e3e4760ae4a5567ca9a474f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/285 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2d710129b004339bdf41c4065fb1fc6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a69f187480cb4b52a2f28cff03945fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/17.8M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-tiny were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-tiny and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "/Users/zaarr/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9002\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1689\n",
      "  Number of trainable parameters = 4395853\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1689' max='1689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1689/1689 04:05, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.354899</td>\n",
       "      <td>0.015984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.352106</td>\n",
       "      <td>0.015984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.347859</td>\n",
       "      <td>0.015984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.342193</td>\n",
       "      <td>0.013986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.333172</td>\n",
       "      <td>0.012987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.322857</td>\n",
       "      <td>0.014985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.309462</td>\n",
       "      <td>0.013986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.294309</td>\n",
       "      <td>0.023976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.257319</td>\n",
       "      <td>0.052947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.329800</td>\n",
       "      <td>4.211791</td>\n",
       "      <td>0.089910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.329800</td>\n",
       "      <td>4.168469</td>\n",
       "      <td>0.126873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.329800</td>\n",
       "      <td>4.113339</td>\n",
       "      <td>0.189810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.329800</td>\n",
       "      <td>4.058489</td>\n",
       "      <td>0.196803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.329800</td>\n",
       "      <td>4.004323</td>\n",
       "      <td>0.236763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.329800</td>\n",
       "      <td>3.952668</td>\n",
       "      <td>0.250749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.329800</td>\n",
       "      <td>3.907843</td>\n",
       "      <td>0.246753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.329800</td>\n",
       "      <td>3.858387</td>\n",
       "      <td>0.273726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.329800</td>\n",
       "      <td>3.816228</td>\n",
       "      <td>0.284715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.329800</td>\n",
       "      <td>3.777663</td>\n",
       "      <td>0.289710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>4.012100</td>\n",
       "      <td>3.736608</td>\n",
       "      <td>0.307692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>4.012100</td>\n",
       "      <td>3.701480</td>\n",
       "      <td>0.331668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>4.012100</td>\n",
       "      <td>3.670484</td>\n",
       "      <td>0.320679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>4.012100</td>\n",
       "      <td>3.640872</td>\n",
       "      <td>0.332667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>4.012100</td>\n",
       "      <td>3.616020</td>\n",
       "      <td>0.354645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>4.012100</td>\n",
       "      <td>3.589586</td>\n",
       "      <td>0.358641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>4.012100</td>\n",
       "      <td>3.571033</td>\n",
       "      <td>0.355644</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>4.012100</td>\n",
       "      <td>3.551897</td>\n",
       "      <td>0.363636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>4.012100</td>\n",
       "      <td>3.534883</td>\n",
       "      <td>0.362637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>4.012100</td>\n",
       "      <td>3.521837</td>\n",
       "      <td>0.366633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>3.662800</td>\n",
       "      <td>3.509973</td>\n",
       "      <td>0.364635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>3.662800</td>\n",
       "      <td>3.502768</td>\n",
       "      <td>0.367632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>3.662800</td>\n",
       "      <td>3.496568</td>\n",
       "      <td>0.371628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>3.662800</td>\n",
       "      <td>3.493391</td>\n",
       "      <td>0.372627</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-50\n",
      "Configuration saved in ./results/checkpoint-50/config.json\n",
      "Model weights saved in ./results/checkpoint-50/pytorch_model.bin\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-100\n",
      "Configuration saved in ./results/checkpoint-100/config.json\n",
      "Model weights saved in ./results/checkpoint-100/pytorch_model.bin\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-150\n",
      "Configuration saved in ./results/checkpoint-150/config.json\n",
      "Model weights saved in ./results/checkpoint-150/pytorch_model.bin\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-200\n",
      "Configuration saved in ./results/checkpoint-200/config.json\n",
      "Model weights saved in ./results/checkpoint-200/pytorch_model.bin\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-250\n",
      "Configuration saved in ./results/checkpoint-250/config.json\n",
      "Model weights saved in ./results/checkpoint-250/pytorch_model.bin\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-300\n",
      "Configuration saved in ./results/checkpoint-300/config.json\n",
      "Model weights saved in ./results/checkpoint-300/pytorch_model.bin\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-350\n",
      "Configuration saved in ./results/checkpoint-350/config.json\n",
      "Model weights saved in ./results/checkpoint-350/pytorch_model.bin\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-400\n",
      "Configuration saved in ./results/checkpoint-400/config.json\n",
      "Model weights saved in ./results/checkpoint-400/pytorch_model.bin\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-450\n",
      "Configuration saved in ./results/checkpoint-450/config.json\n",
      "Model weights saved in ./results/checkpoint-450/pytorch_model.bin\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-550\n",
      "Configuration saved in ./results/checkpoint-550/config.json\n",
      "Model weights saved in ./results/checkpoint-550/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-50] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-600\n",
      "Configuration saved in ./results/checkpoint-600/config.json\n",
      "Model weights saved in ./results/checkpoint-600/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-100] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-650\n",
      "Configuration saved in ./results/checkpoint-650/config.json\n",
      "Model weights saved in ./results/checkpoint-650/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-150] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-700\n",
      "Configuration saved in ./results/checkpoint-700/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results/checkpoint-700/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-200] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-750\n",
      "Configuration saved in ./results/checkpoint-750/config.json\n",
      "Model weights saved in ./results/checkpoint-750/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-250] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-800\n",
      "Configuration saved in ./results/checkpoint-800/config.json\n",
      "Model weights saved in ./results/checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-300] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-850\n",
      "Configuration saved in ./results/checkpoint-850/config.json\n",
      "Model weights saved in ./results/checkpoint-850/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-350] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-900\n",
      "Configuration saved in ./results/checkpoint-900/config.json\n",
      "Model weights saved in ./results/checkpoint-900/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-400] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-950\n",
      "Configuration saved in ./results/checkpoint-950/config.json\n",
      "Model weights saved in ./results/checkpoint-950/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-450] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1050\n",
      "Configuration saved in ./results/checkpoint-1050/config.json\n",
      "Model weights saved in ./results/checkpoint-1050/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-550] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1100\n",
      "Configuration saved in ./results/checkpoint-1100/config.json\n",
      "Model weights saved in ./results/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-600] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1150\n",
      "Configuration saved in ./results/checkpoint-1150/config.json\n",
      "Model weights saved in ./results/checkpoint-1150/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-650] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1200\n",
      "Configuration saved in ./results/checkpoint-1200/config.json\n",
      "Model weights saved in ./results/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-700] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1250\n",
      "Configuration saved in ./results/checkpoint-1250/config.json\n",
      "Model weights saved in ./results/checkpoint-1250/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-750] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1300\n",
      "Configuration saved in ./results/checkpoint-1300/config.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ./results/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-800] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1350\n",
      "Configuration saved in ./results/checkpoint-1350/config.json\n",
      "Model weights saved in ./results/checkpoint-1350/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-850] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1400\n",
      "Configuration saved in ./results/checkpoint-1400/config.json\n",
      "Model weights saved in ./results/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-900] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1450\n",
      "Configuration saved in ./results/checkpoint-1450/config.json\n",
      "Model weights saved in ./results/checkpoint-1450/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-950] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1550\n",
      "Configuration saved in ./results/checkpoint-1550/config.json\n",
      "Model weights saved in ./results/checkpoint-1550/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1050] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1600\n",
      "Configuration saved in ./results/checkpoint-1600/config.json\n",
      "Model weights saved in ./results/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1100] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1650\n",
      "Configuration saved in ./results/checkpoint-1650/config.json\n",
      "Model weights saved in ./results/checkpoint-1650/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1150] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-1650 (score: 3.4933907985687256).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:04]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** prajjwal1/bert-mini ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "204f9ed656c740fd91167aa6c1e1ee93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-mini/snapshots/5e123abc2480f0c4b4cac186d3b3f09299c258fc/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-mini\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211a1d41da8e47778e1112715e83cc6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-mini/snapshots/5e123abc2480f0c4b4cac186d3b3f09299c258fc/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-mini/snapshots/5e123abc2480f0c4b4cac186d3b3f09299c258fc/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-mini\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-mini/snapshots/5e123abc2480f0c4b4cac186d3b3f09299c258fc/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-mini\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-mini/snapshots/5e123abc2480f0c4b4cac186d3b3f09299c258fc/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-mini\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 256,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 1024,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 4,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7ebd2ec0e3a44deb9e5ac8aff93d434",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/45.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-mini/snapshots/5e123abc2480f0c4b4cac186d3b3f09299c258fc/pytorch_model.bin\n",
      "Some weights of the model checkpoint at prajjwal1/bert-mini were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-mini and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/Users/zaarr/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9002\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1689\n",
      "  Number of trainable parameters = 11190349\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1689' max='1689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1689/1689 17:59, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.356071</td>\n",
       "      <td>0.019980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.346424</td>\n",
       "      <td>0.015984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.328240</td>\n",
       "      <td>0.021978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.308884</td>\n",
       "      <td>0.026973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.278137</td>\n",
       "      <td>0.034965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.239903</td>\n",
       "      <td>0.045954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.176839</td>\n",
       "      <td>0.084915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.120913</td>\n",
       "      <td>0.114885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.984796</td>\n",
       "      <td>0.170829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.244300</td>\n",
       "      <td>3.855187</td>\n",
       "      <td>0.268731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>4.244300</td>\n",
       "      <td>3.705956</td>\n",
       "      <td>0.321678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>4.244300</td>\n",
       "      <td>3.557374</td>\n",
       "      <td>0.367632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>4.244300</td>\n",
       "      <td>3.412239</td>\n",
       "      <td>0.420579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>4.244300</td>\n",
       "      <td>3.291900</td>\n",
       "      <td>0.442557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>4.244300</td>\n",
       "      <td>3.180168</td>\n",
       "      <td>0.498501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>4.244300</td>\n",
       "      <td>3.081021</td>\n",
       "      <td>0.502498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>4.244300</td>\n",
       "      <td>2.971816</td>\n",
       "      <td>0.530470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>4.244300</td>\n",
       "      <td>2.887461</td>\n",
       "      <td>0.539461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>4.244300</td>\n",
       "      <td>2.822308</td>\n",
       "      <td>0.535465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>3.311400</td>\n",
       "      <td>2.743449</td>\n",
       "      <td>0.577423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>3.311400</td>\n",
       "      <td>2.682368</td>\n",
       "      <td>0.573427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>3.311400</td>\n",
       "      <td>2.619125</td>\n",
       "      <td>0.594406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>3.311400</td>\n",
       "      <td>2.572234</td>\n",
       "      <td>0.589411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>3.311400</td>\n",
       "      <td>2.528006</td>\n",
       "      <td>0.607393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>3.311400</td>\n",
       "      <td>2.473167</td>\n",
       "      <td>0.608392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>3.311400</td>\n",
       "      <td>2.439518</td>\n",
       "      <td>0.603397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>3.311400</td>\n",
       "      <td>2.403704</td>\n",
       "      <td>0.617383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>3.311400</td>\n",
       "      <td>2.372349</td>\n",
       "      <td>0.624376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>3.311400</td>\n",
       "      <td>2.350184</td>\n",
       "      <td>0.622378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>2.570800</td>\n",
       "      <td>2.329062</td>\n",
       "      <td>0.628372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>2.570800</td>\n",
       "      <td>2.314640</td>\n",
       "      <td>0.635365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>2.570800</td>\n",
       "      <td>2.304442</td>\n",
       "      <td>0.637363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>2.570800</td>\n",
       "      <td>2.299211</td>\n",
       "      <td>0.645355</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-50\n",
      "Configuration saved in ./results/checkpoint-50/config.json\n",
      "Model weights saved in ./results/checkpoint-50/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1200] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-100\n",
      "Configuration saved in ./results/checkpoint-100/config.json\n",
      "Model weights saved in ./results/checkpoint-100/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1250] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-150\n",
      "Configuration saved in ./results/checkpoint-150/config.json\n",
      "Model weights saved in ./results/checkpoint-150/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1300] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-200\n",
      "Configuration saved in ./results/checkpoint-200/config.json\n",
      "Model weights saved in ./results/checkpoint-200/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1350] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-250\n",
      "Configuration saved in ./results/checkpoint-250/config.json\n",
      "Model weights saved in ./results/checkpoint-250/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1400] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-300\n",
      "Configuration saved in ./results/checkpoint-300/config.json\n",
      "Model weights saved in ./results/checkpoint-300/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1450] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-350\n",
      "Configuration saved in ./results/checkpoint-350/config.json\n",
      "Model weights saved in ./results/checkpoint-350/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-400\n",
      "Configuration saved in ./results/checkpoint-400/config.json\n",
      "Model weights saved in ./results/checkpoint-400/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1550] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-450\n",
      "Configuration saved in ./results/checkpoint-450/config.json\n",
      "Model weights saved in ./results/checkpoint-450/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1600] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1650] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-550\n",
      "Configuration saved in ./results/checkpoint-550/config.json\n",
      "Model weights saved in ./results/checkpoint-550/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-50] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-600\n",
      "Configuration saved in ./results/checkpoint-600/config.json\n",
      "Model weights saved in ./results/checkpoint-600/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-100] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-650\n",
      "Configuration saved in ./results/checkpoint-650/config.json\n",
      "Model weights saved in ./results/checkpoint-650/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-150] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-700\n",
      "Configuration saved in ./results/checkpoint-700/config.json\n",
      "Model weights saved in ./results/checkpoint-700/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-200] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-750\n",
      "Configuration saved in ./results/checkpoint-750/config.json\n",
      "Model weights saved in ./results/checkpoint-750/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-250] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-800\n",
      "Configuration saved in ./results/checkpoint-800/config.json\n",
      "Model weights saved in ./results/checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-300] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-850\n",
      "Configuration saved in ./results/checkpoint-850/config.json\n",
      "Model weights saved in ./results/checkpoint-850/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-350] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-900\n",
      "Configuration saved in ./results/checkpoint-900/config.json\n",
      "Model weights saved in ./results/checkpoint-900/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-400] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-950\n",
      "Configuration saved in ./results/checkpoint-950/config.json\n",
      "Model weights saved in ./results/checkpoint-950/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-450] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1050\n",
      "Configuration saved in ./results/checkpoint-1050/config.json\n",
      "Model weights saved in ./results/checkpoint-1050/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-550] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1100\n",
      "Configuration saved in ./results/checkpoint-1100/config.json\n",
      "Model weights saved in ./results/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-600] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1150\n",
      "Configuration saved in ./results/checkpoint-1150/config.json\n",
      "Model weights saved in ./results/checkpoint-1150/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-650] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1200\n",
      "Configuration saved in ./results/checkpoint-1200/config.json\n",
      "Model weights saved in ./results/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-700] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1250\n",
      "Configuration saved in ./results/checkpoint-1250/config.json\n",
      "Model weights saved in ./results/checkpoint-1250/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-750] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1300\n",
      "Configuration saved in ./results/checkpoint-1300/config.json\n",
      "Model weights saved in ./results/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-800] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1350\n",
      "Configuration saved in ./results/checkpoint-1350/config.json\n",
      "Model weights saved in ./results/checkpoint-1350/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-850] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1400\n",
      "Configuration saved in ./results/checkpoint-1400/config.json\n",
      "Model weights saved in ./results/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-900] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1450\n",
      "Configuration saved in ./results/checkpoint-1450/config.json\n",
      "Model weights saved in ./results/checkpoint-1450/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-950] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1550\n",
      "Configuration saved in ./results/checkpoint-1550/config.json\n",
      "Model weights saved in ./results/checkpoint-1550/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1050] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1600\n",
      "Configuration saved in ./results/checkpoint-1600/config.json\n",
      "Model weights saved in ./results/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1100] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1650\n",
      "Configuration saved in ./results/checkpoint-1650/config.json\n",
      "Model weights saved in ./results/checkpoint-1650/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1150] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-1650 (score: 2.299210786819458).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** prajjwal1/bert-small ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec5c3566cf9941c2a06fe6833fb12282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-small/snapshots/0ec5f86f27c1a77d704439db5e01c307ea11b9d4/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ff1380db679426085ba34f4e774f23a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-small/snapshots/0ec5f86f27c1a77d704439db5e01c307ea11b9d4/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-small/snapshots/0ec5f86f27c1a77d704439db5e01c307ea11b9d4/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-small/snapshots/0ec5f86f27c1a77d704439db5e01c307ea11b9d4/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-small/snapshots/0ec5f86f27c1a77d704439db5e01c307ea11b9d4/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-small\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 4,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca40753f063a4e1988586aebf8fb6f9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/116M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-small/snapshots/0ec5f86f27c1a77d704439db5e01c307ea11b9d4/pytorch_model.bin\n",
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-small and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/Users/zaarr/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9002\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1689\n",
      "  Number of trainable parameters = 28803149\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1689' max='1689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1689/1689 1:23:35, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.363510</td>\n",
       "      <td>0.009990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.319171</td>\n",
       "      <td>0.015984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.266430</td>\n",
       "      <td>0.014985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.180545</td>\n",
       "      <td>0.062937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.032411</td>\n",
       "      <td>0.166833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.803262</td>\n",
       "      <td>0.271728</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.504495</td>\n",
       "      <td>0.400599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.230228</td>\n",
       "      <td>0.432567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.897503</td>\n",
       "      <td>0.526474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.877900</td>\n",
       "      <td>2.638017</td>\n",
       "      <td>0.550450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.877900</td>\n",
       "      <td>2.356631</td>\n",
       "      <td>0.609391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.877900</td>\n",
       "      <td>2.097563</td>\n",
       "      <td>0.620380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.877900</td>\n",
       "      <td>1.897394</td>\n",
       "      <td>0.653347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.877900</td>\n",
       "      <td>1.713191</td>\n",
       "      <td>0.697303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.877900</td>\n",
       "      <td>1.548452</td>\n",
       "      <td>0.749251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.877900</td>\n",
       "      <td>1.445564</td>\n",
       "      <td>0.752248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.877900</td>\n",
       "      <td>1.310407</td>\n",
       "      <td>0.797203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.877900</td>\n",
       "      <td>1.230697</td>\n",
       "      <td>0.812188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.877900</td>\n",
       "      <td>1.154832</td>\n",
       "      <td>0.811189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>1.071555</td>\n",
       "      <td>0.841159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>1.012782</td>\n",
       "      <td>0.832168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>0.968622</td>\n",
       "      <td>0.851149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>0.924169</td>\n",
       "      <td>0.850150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>0.871055</td>\n",
       "      <td>0.862138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>0.832074</td>\n",
       "      <td>0.869131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>0.816757</td>\n",
       "      <td>0.854146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>0.788408</td>\n",
       "      <td>0.872128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>0.761575</td>\n",
       "      <td>0.869131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.802900</td>\n",
       "      <td>0.741266</td>\n",
       "      <td>0.875125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.935400</td>\n",
       "      <td>0.725301</td>\n",
       "      <td>0.876124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.935400</td>\n",
       "      <td>0.719297</td>\n",
       "      <td>0.874126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.935400</td>\n",
       "      <td>0.709098</td>\n",
       "      <td>0.870130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.935400</td>\n",
       "      <td>0.702773</td>\n",
       "      <td>0.872128</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-50\n",
      "Configuration saved in ./results/checkpoint-50/config.json\n",
      "Model weights saved in ./results/checkpoint-50/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1200] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-100\n",
      "Configuration saved in ./results/checkpoint-100/config.json\n",
      "Model weights saved in ./results/checkpoint-100/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1250] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-150\n",
      "Configuration saved in ./results/checkpoint-150/config.json\n",
      "Model weights saved in ./results/checkpoint-150/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1300] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-200\n",
      "Configuration saved in ./results/checkpoint-200/config.json\n",
      "Model weights saved in ./results/checkpoint-200/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1350] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-250\n",
      "Configuration saved in ./results/checkpoint-250/config.json\n",
      "Model weights saved in ./results/checkpoint-250/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1400] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-300\n",
      "Configuration saved in ./results/checkpoint-300/config.json\n",
      "Model weights saved in ./results/checkpoint-300/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1450] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-350\n",
      "Configuration saved in ./results/checkpoint-350/config.json\n",
      "Model weights saved in ./results/checkpoint-350/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-400\n",
      "Configuration saved in ./results/checkpoint-400/config.json\n",
      "Model weights saved in ./results/checkpoint-400/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1550] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-450\n",
      "Configuration saved in ./results/checkpoint-450/config.json\n",
      "Model weights saved in ./results/checkpoint-450/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1600] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1650] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-550\n",
      "Configuration saved in ./results/checkpoint-550/config.json\n",
      "Model weights saved in ./results/checkpoint-550/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-50] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-600\n",
      "Configuration saved in ./results/checkpoint-600/config.json\n",
      "Model weights saved in ./results/checkpoint-600/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-100] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-650\n",
      "Configuration saved in ./results/checkpoint-650/config.json\n",
      "Model weights saved in ./results/checkpoint-650/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-150] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-700\n",
      "Configuration saved in ./results/checkpoint-700/config.json\n",
      "Model weights saved in ./results/checkpoint-700/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-200] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-750\n",
      "Configuration saved in ./results/checkpoint-750/config.json\n",
      "Model weights saved in ./results/checkpoint-750/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-250] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-800\n",
      "Configuration saved in ./results/checkpoint-800/config.json\n",
      "Model weights saved in ./results/checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-300] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-850\n",
      "Configuration saved in ./results/checkpoint-850/config.json\n",
      "Model weights saved in ./results/checkpoint-850/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-350] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-900\n",
      "Configuration saved in ./results/checkpoint-900/config.json\n",
      "Model weights saved in ./results/checkpoint-900/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-400] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-950\n",
      "Configuration saved in ./results/checkpoint-950/config.json\n",
      "Model weights saved in ./results/checkpoint-950/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-450] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1050\n",
      "Configuration saved in ./results/checkpoint-1050/config.json\n",
      "Model weights saved in ./results/checkpoint-1050/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-550] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1100\n",
      "Configuration saved in ./results/checkpoint-1100/config.json\n",
      "Model weights saved in ./results/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-600] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1150\n",
      "Configuration saved in ./results/checkpoint-1150/config.json\n",
      "Model weights saved in ./results/checkpoint-1150/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-650] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1200\n",
      "Configuration saved in ./results/checkpoint-1200/config.json\n",
      "Model weights saved in ./results/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-700] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1250\n",
      "Configuration saved in ./results/checkpoint-1250/config.json\n",
      "Model weights saved in ./results/checkpoint-1250/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-750] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1300\n",
      "Configuration saved in ./results/checkpoint-1300/config.json\n",
      "Model weights saved in ./results/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-800] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1350\n",
      "Configuration saved in ./results/checkpoint-1350/config.json\n",
      "Model weights saved in ./results/checkpoint-1350/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-850] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1400\n",
      "Configuration saved in ./results/checkpoint-1400/config.json\n",
      "Model weights saved in ./results/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-900] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1450\n",
      "Configuration saved in ./results/checkpoint-1450/config.json\n",
      "Model weights saved in ./results/checkpoint-1450/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-950] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1550\n",
      "Configuration saved in ./results/checkpoint-1550/config.json\n",
      "Model weights saved in ./results/checkpoint-1550/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1050] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1600\n",
      "Configuration saved in ./results/checkpoint-1600/config.json\n",
      "Model weights saved in ./results/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1100] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1650\n",
      "Configuration saved in ./results/checkpoint-1650/config.json\n",
      "Model weights saved in ./results/checkpoint-1650/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1150] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-1650 (score: 0.7027731537818909).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 01:02]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** prajjwal1/bert-medium ***\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6b4a1f1829744998ee63b50cbe344f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/286 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-medium/snapshots/ce27ec2944bd32b66ed837edb9c77eb7301b8ecc/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-medium\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a09f5a26e99a497fadd5beabb3aa16c1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file vocab.txt from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-medium/snapshots/ce27ec2944bd32b66ed837edb9c77eb7301b8ecc/vocab.txt\n",
      "loading file tokenizer.json from cache at None\n",
      "loading file added_tokens.json from cache at None\n",
      "loading file special_tokens_map.json from cache at None\n",
      "loading file tokenizer_config.json from cache at None\n",
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-medium/snapshots/ce27ec2944bd32b66ed837edb9c77eb7301b8ecc/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-medium\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-medium/snapshots/ce27ec2944bd32b66ed837edb9c77eb7301b8ecc/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-medium\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading configuration file config.json from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-medium/snapshots/ce27ec2944bd32b66ed837edb9c77eb7301b8ecc/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"prajjwal1/bert-medium\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 512,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\",\n",
      "    \"15\": \"LABEL_15\",\n",
      "    \"16\": \"LABEL_16\",\n",
      "    \"17\": \"LABEL_17\",\n",
      "    \"18\": \"LABEL_18\",\n",
      "    \"19\": \"LABEL_19\",\n",
      "    \"20\": \"LABEL_20\",\n",
      "    \"21\": \"LABEL_21\",\n",
      "    \"22\": \"LABEL_22\",\n",
      "    \"23\": \"LABEL_23\",\n",
      "    \"24\": \"LABEL_24\",\n",
      "    \"25\": \"LABEL_25\",\n",
      "    \"26\": \"LABEL_26\",\n",
      "    \"27\": \"LABEL_27\",\n",
      "    \"28\": \"LABEL_28\",\n",
      "    \"29\": \"LABEL_29\",\n",
      "    \"30\": \"LABEL_30\",\n",
      "    \"31\": \"LABEL_31\",\n",
      "    \"32\": \"LABEL_32\",\n",
      "    \"33\": \"LABEL_33\",\n",
      "    \"34\": \"LABEL_34\",\n",
      "    \"35\": \"LABEL_35\",\n",
      "    \"36\": \"LABEL_36\",\n",
      "    \"37\": \"LABEL_37\",\n",
      "    \"38\": \"LABEL_38\",\n",
      "    \"39\": \"LABEL_39\",\n",
      "    \"40\": \"LABEL_40\",\n",
      "    \"41\": \"LABEL_41\",\n",
      "    \"42\": \"LABEL_42\",\n",
      "    \"43\": \"LABEL_43\",\n",
      "    \"44\": \"LABEL_44\",\n",
      "    \"45\": \"LABEL_45\",\n",
      "    \"46\": \"LABEL_46\",\n",
      "    \"47\": \"LABEL_47\",\n",
      "    \"48\": \"LABEL_48\",\n",
      "    \"49\": \"LABEL_49\",\n",
      "    \"50\": \"LABEL_50\",\n",
      "    \"51\": \"LABEL_51\",\n",
      "    \"52\": \"LABEL_52\",\n",
      "    \"53\": \"LABEL_53\",\n",
      "    \"54\": \"LABEL_54\",\n",
      "    \"55\": \"LABEL_55\",\n",
      "    \"56\": \"LABEL_56\",\n",
      "    \"57\": \"LABEL_57\",\n",
      "    \"58\": \"LABEL_58\",\n",
      "    \"59\": \"LABEL_59\",\n",
      "    \"60\": \"LABEL_60\",\n",
      "    \"61\": \"LABEL_61\",\n",
      "    \"62\": \"LABEL_62\",\n",
      "    \"63\": \"LABEL_63\",\n",
      "    \"64\": \"LABEL_64\",\n",
      "    \"65\": \"LABEL_65\",\n",
      "    \"66\": \"LABEL_66\",\n",
      "    \"67\": \"LABEL_67\",\n",
      "    \"68\": \"LABEL_68\",\n",
      "    \"69\": \"LABEL_69\",\n",
      "    \"70\": \"LABEL_70\",\n",
      "    \"71\": \"LABEL_71\",\n",
      "    \"72\": \"LABEL_72\",\n",
      "    \"73\": \"LABEL_73\",\n",
      "    \"74\": \"LABEL_74\",\n",
      "    \"75\": \"LABEL_75\",\n",
      "    \"76\": \"LABEL_76\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 2048,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_15\": 15,\n",
      "    \"LABEL_16\": 16,\n",
      "    \"LABEL_17\": 17,\n",
      "    \"LABEL_18\": 18,\n",
      "    \"LABEL_19\": 19,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_20\": 20,\n",
      "    \"LABEL_21\": 21,\n",
      "    \"LABEL_22\": 22,\n",
      "    \"LABEL_23\": 23,\n",
      "    \"LABEL_24\": 24,\n",
      "    \"LABEL_25\": 25,\n",
      "    \"LABEL_26\": 26,\n",
      "    \"LABEL_27\": 27,\n",
      "    \"LABEL_28\": 28,\n",
      "    \"LABEL_29\": 29,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_30\": 30,\n",
      "    \"LABEL_31\": 31,\n",
      "    \"LABEL_32\": 32,\n",
      "    \"LABEL_33\": 33,\n",
      "    \"LABEL_34\": 34,\n",
      "    \"LABEL_35\": 35,\n",
      "    \"LABEL_36\": 36,\n",
      "    \"LABEL_37\": 37,\n",
      "    \"LABEL_38\": 38,\n",
      "    \"LABEL_39\": 39,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_40\": 40,\n",
      "    \"LABEL_41\": 41,\n",
      "    \"LABEL_42\": 42,\n",
      "    \"LABEL_43\": 43,\n",
      "    \"LABEL_44\": 44,\n",
      "    \"LABEL_45\": 45,\n",
      "    \"LABEL_46\": 46,\n",
      "    \"LABEL_47\": 47,\n",
      "    \"LABEL_48\": 48,\n",
      "    \"LABEL_49\": 49,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_50\": 50,\n",
      "    \"LABEL_51\": 51,\n",
      "    \"LABEL_52\": 52,\n",
      "    \"LABEL_53\": 53,\n",
      "    \"LABEL_54\": 54,\n",
      "    \"LABEL_55\": 55,\n",
      "    \"LABEL_56\": 56,\n",
      "    \"LABEL_57\": 57,\n",
      "    \"LABEL_58\": 58,\n",
      "    \"LABEL_59\": 59,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_60\": 60,\n",
      "    \"LABEL_61\": 61,\n",
      "    \"LABEL_62\": 62,\n",
      "    \"LABEL_63\": 63,\n",
      "    \"LABEL_64\": 64,\n",
      "    \"LABEL_65\": 65,\n",
      "    \"LABEL_66\": 66,\n",
      "    \"LABEL_67\": 67,\n",
      "    \"LABEL_68\": 68,\n",
      "    \"LABEL_69\": 69,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_70\": 70,\n",
      "    \"LABEL_71\": 71,\n",
      "    \"LABEL_72\": 72,\n",
      "    \"LABEL_73\": 73,\n",
      "    \"LABEL_74\": 74,\n",
      "    \"LABEL_75\": 75,\n",
      "    \"LABEL_76\": 76,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 8,\n",
      "  \"num_hidden_layers\": 8,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.24.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "883b2ef0864f41f58f487533894bfdcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/167M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading weights file pytorch_model.bin from cache at /Users/zaarr/.cache/huggingface/hub/models--prajjwal1--bert-medium/snapshots/ce27ec2944bd32b66ed837edb9c77eb7301b8ecc/pytorch_model.bin\n",
      "Some weights of the model checkpoint at prajjwal1/bert-medium were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at prajjwal1/bert-medium and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "/Users/zaarr/opt/anaconda3/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9002\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1689\n",
      "  Number of trainable parameters = 41412685\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1689' max='1689' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1689/1689 8:44:14, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.334461</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.291095</td>\n",
       "      <td>0.033966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.220604</td>\n",
       "      <td>0.070929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>No log</td>\n",
       "      <td>4.084690</td>\n",
       "      <td>0.157842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.852195</td>\n",
       "      <td>0.258741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.570946</td>\n",
       "      <td>0.413586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>No log</td>\n",
       "      <td>3.249877</td>\n",
       "      <td>0.490509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.953640</td>\n",
       "      <td>0.529471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>No log</td>\n",
       "      <td>2.647262</td>\n",
       "      <td>0.587413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>3.742700</td>\n",
       "      <td>2.372876</td>\n",
       "      <td>0.631369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>3.742700</td>\n",
       "      <td>2.109050</td>\n",
       "      <td>0.693307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.742700</td>\n",
       "      <td>1.850331</td>\n",
       "      <td>0.711289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>3.742700</td>\n",
       "      <td>1.644721</td>\n",
       "      <td>0.749251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.742700</td>\n",
       "      <td>1.468404</td>\n",
       "      <td>0.781219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>3.742700</td>\n",
       "      <td>1.339557</td>\n",
       "      <td>0.803197</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>3.742700</td>\n",
       "      <td>1.205506</td>\n",
       "      <td>0.794206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>850</td>\n",
       "      <td>3.742700</td>\n",
       "      <td>1.102818</td>\n",
       "      <td>0.829171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>3.742700</td>\n",
       "      <td>1.016320</td>\n",
       "      <td>0.834166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>950</td>\n",
       "      <td>3.742700</td>\n",
       "      <td>0.939365</td>\n",
       "      <td>0.850150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>0.874223</td>\n",
       "      <td>0.863137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1050</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>0.818843</td>\n",
       "      <td>0.872128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>0.779198</td>\n",
       "      <td>0.864136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1150</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>0.736847</td>\n",
       "      <td>0.867133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>0.690144</td>\n",
       "      <td>0.872128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1250</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>0.670957</td>\n",
       "      <td>0.880120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>0.645357</td>\n",
       "      <td>0.882118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1350</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>0.627144</td>\n",
       "      <td>0.884116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>0.597268</td>\n",
       "      <td>0.886114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1450</td>\n",
       "      <td>1.537000</td>\n",
       "      <td>0.587931</td>\n",
       "      <td>0.886114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.569705</td>\n",
       "      <td>0.891109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1550</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.558096</td>\n",
       "      <td>0.893107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.545196</td>\n",
       "      <td>0.899101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1650</td>\n",
       "      <td>0.697400</td>\n",
       "      <td>0.538390</td>\n",
       "      <td>0.896104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-50\n",
      "Configuration saved in ./results/checkpoint-50/config.json\n",
      "Model weights saved in ./results/checkpoint-50/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1200] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-100\n",
      "Configuration saved in ./results/checkpoint-100/config.json\n",
      "Model weights saved in ./results/checkpoint-100/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1250] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-150\n",
      "Configuration saved in ./results/checkpoint-150/config.json\n",
      "Model weights saved in ./results/checkpoint-150/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1300] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-200\n",
      "Configuration saved in ./results/checkpoint-200/config.json\n",
      "Model weights saved in ./results/checkpoint-200/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1350] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-250\n",
      "Configuration saved in ./results/checkpoint-250/config.json\n",
      "Model weights saved in ./results/checkpoint-250/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1400] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-300\n",
      "Configuration saved in ./results/checkpoint-300/config.json\n",
      "Model weights saved in ./results/checkpoint-300/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1450] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-350\n",
      "Configuration saved in ./results/checkpoint-350/config.json\n",
      "Model weights saved in ./results/checkpoint-350/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1500] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-400\n",
      "Configuration saved in ./results/checkpoint-400/config.json\n",
      "Model weights saved in ./results/checkpoint-400/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1550] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-450\n",
      "Configuration saved in ./results/checkpoint-450/config.json\n",
      "Model weights saved in ./results/checkpoint-450/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1600] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-500\n",
      "Configuration saved in ./results/checkpoint-500/config.json\n",
      "Model weights saved in ./results/checkpoint-500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1650] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-550\n",
      "Configuration saved in ./results/checkpoint-550/config.json\n",
      "Model weights saved in ./results/checkpoint-550/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-50] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-600\n",
      "Configuration saved in ./results/checkpoint-600/config.json\n",
      "Model weights saved in ./results/checkpoint-600/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-100] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-650\n",
      "Configuration saved in ./results/checkpoint-650/config.json\n",
      "Model weights saved in ./results/checkpoint-650/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-150] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-700\n",
      "Configuration saved in ./results/checkpoint-700/config.json\n",
      "Model weights saved in ./results/checkpoint-700/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-200] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-750\n",
      "Configuration saved in ./results/checkpoint-750/config.json\n",
      "Model weights saved in ./results/checkpoint-750/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-250] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-800\n",
      "Configuration saved in ./results/checkpoint-800/config.json\n",
      "Model weights saved in ./results/checkpoint-800/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-300] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-850\n",
      "Configuration saved in ./results/checkpoint-850/config.json\n",
      "Model weights saved in ./results/checkpoint-850/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-350] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-900\n",
      "Configuration saved in ./results/checkpoint-900/config.json\n",
      "Model weights saved in ./results/checkpoint-900/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-400] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-950\n",
      "Configuration saved in ./results/checkpoint-950/config.json\n",
      "Model weights saved in ./results/checkpoint-950/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-450] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1000\n",
      "Configuration saved in ./results/checkpoint-1000/config.json\n",
      "Model weights saved in ./results/checkpoint-1000/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-500] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1050\n",
      "Configuration saved in ./results/checkpoint-1050/config.json\n",
      "Model weights saved in ./results/checkpoint-1050/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-550] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1100\n",
      "Configuration saved in ./results/checkpoint-1100/config.json\n",
      "Model weights saved in ./results/checkpoint-1100/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-600] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1150\n",
      "Configuration saved in ./results/checkpoint-1150/config.json\n",
      "Model weights saved in ./results/checkpoint-1150/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-650] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1200\n",
      "Configuration saved in ./results/checkpoint-1200/config.json\n",
      "Model weights saved in ./results/checkpoint-1200/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-700] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1250\n",
      "Configuration saved in ./results/checkpoint-1250/config.json\n",
      "Model weights saved in ./results/checkpoint-1250/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-750] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1300\n",
      "Configuration saved in ./results/checkpoint-1300/config.json\n",
      "Model weights saved in ./results/checkpoint-1300/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-800] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1350\n",
      "Configuration saved in ./results/checkpoint-1350/config.json\n",
      "Model weights saved in ./results/checkpoint-1350/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-850] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1400\n",
      "Configuration saved in ./results/checkpoint-1400/config.json\n",
      "Model weights saved in ./results/checkpoint-1400/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-900] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1450\n",
      "Configuration saved in ./results/checkpoint-1450/config.json\n",
      "Model weights saved in ./results/checkpoint-1450/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-950] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1500\n",
      "Configuration saved in ./results/checkpoint-1500/config.json\n",
      "Model weights saved in ./results/checkpoint-1500/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1000] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1550\n",
      "Configuration saved in ./results/checkpoint-1550/config.json\n",
      "Model weights saved in ./results/checkpoint-1550/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1050] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1600\n",
      "Configuration saved in ./results/checkpoint-1600/config.json\n",
      "Model weights saved in ./results/checkpoint-1600/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1100] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 1001\n",
      "  Batch size = 64\n",
      "Saving model checkpoint to ./results/checkpoint-1650\n",
      "Configuration saved in ./results/checkpoint-1650/config.json\n",
      "Model weights saved in ./results/checkpoint-1650/pytorch_model.bin\n",
      "Deleting older checkpoint [results/checkpoint-1150] due to args.save_total_limit\n",
      "/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/48522100.py:9: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Loading best model from ./results/checkpoint-1650 (score: 0.5383901000022888).\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 3080\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='49' max='49' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [49/49 5:07:48]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** albert-base-v2 ***\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/zaarr/.cache/huggingface/hub/models--albert-base-v2/refs/main'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/6_/d50lgm19265fhn6q8znq45040000gn/T/ipykernel_4750/1324222643.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"*** {model_id} ***\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAutoModelForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m         \u001b[0;31m# Next, let's try to use the tokenizer_config file to get the tokenizer class.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m         \u001b[0mtokenizer_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_tokenizer_config\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"_commit_hash\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer_config\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/models/auto/tokenization_auto.py\u001b[0m in \u001b[0;36mget_tokenizer_config\u001b[0;34m(pretrained_model_name_or_path, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, **kwargs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     ```\"\"\"\n\u001b[1;32m    411\u001b[0m     \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_commit_hash\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 412\u001b[0;31m     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m    413\u001b[0m         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, use_auth_token, revision, local_files_only, subfolder, user_agent, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash)\u001b[0m\n\u001b[1;32m    407\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    408\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 409\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    410\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    411\u001b[0m             \u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/huggingface_hub/file_download.py\u001b[0m in \u001b[0;36mhf_hub_download\u001b[0;34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, user_agent, force_download, force_filename, proxies, etag_timeout, resume_download, use_auth_token, local_files_only, legacy_cache_layout)\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m             \u001b[0mref_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"refs\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrevision\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1136\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mref_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1137\u001b[0m                 \u001b[0mcommit_hash\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/zaarr/.cache/huggingface/hub/models--albert-base-v2/refs/main'"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, Trainer, TrainingArguments, AutoModelForSequenceClassification\n",
    "\n",
    "model_ids = [\"prajjwal1/bert-tiny\", \"prajjwal1/bert-mini\", \n",
    "             \"prajjwal1/bert-small\", \"prajjwal1/bert-medium\",\n",
    "             \"albert-base-v2\", \"albert-large-v2\", \"bert-base-uncased\"]\n",
    "\n",
    "accuracies = []\n",
    "for model_id in model_ids:\n",
    "    \n",
    "    print(f\"*** {model_id} ***\")\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "    model = AutoModelForSequenceClassification.from_pretrained(model_id, num_labels=len(label_names))\n",
    "\n",
    "    train_texts_encoded = tokenizer(train_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    dev_texts_encoded = tokenizer(dev_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    test_texts_encoded = tokenizer(test_texts, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "    \n",
    "    train_dataset = ClassificationDataset(train_texts_encoded, train_labels)\n",
    "    dev_dataset = ClassificationDataset(dev_texts_encoded, dev_labels)\n",
    "    test_dataset = ClassificationDataset(test_texts_encoded, test_labels)\n",
    "    \n",
    "    training_args = TrainingArguments(\n",
    "        output_dir='./results',\n",
    "        num_train_epochs=3,\n",
    "        per_device_train_batch_size=16,\n",
    "        per_device_eval_batch_size=64,\n",
    "        warmup_steps=int(len(train_dataset)/16),\n",
    "        weight_decay=0.01,\n",
    "        logging_dir='./logs',\n",
    "        evaluation_strategy=\"steps\",\n",
    "        eval_steps=50,\n",
    "        save_steps=50,\n",
    "        save_total_limit=10,\n",
    "        load_best_model_at_end=True,\n",
    "        no_cuda=False\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        compute_metrics=compute_metrics,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=dev_dataset,\n",
    "    )\n",
    "\n",
    "    trainer.train()\n",
    "    test_results = trainer.evaluate(test_dataset)\n",
    "    \n",
    "    accuracies.append(test_results[\"eval_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c72b94a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.DataFrame({\"model\": accuracies}, index=model_ids)\n",
    "\n",
    "print(df)\n",
    "plt.rcParams['figure.figsize'] = (10,6)\n",
    "ax = df.transpose().plot(kind=\"bar\", rot=0)\n",
    "ax.legend(loc=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
